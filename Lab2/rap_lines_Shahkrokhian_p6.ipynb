{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biggie Smalls and 2Pac Rap dataset using the Shahkrokhian implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"example_spam.csv\",delimiter=\",\",names = ['label','message'])\n",
    "\n",
    "#Uploading dataset from biggie\n",
    "biggie_df = pd.read_csv('./unigrams_NB_clasiffiers/biggie_lyrics.csv',usecols=[1],encoding='latin-1',header=None)\n",
    "biggie_df.columns = ['lyrics']\n",
    "biggie_df['lyrics'] = biggie_df['lyrics'].str.replace('[^\\w\\s]','')\n",
    "biggie_df['lyrics'] = biggie_df['lyrics'].str.lower()\n",
    "\n",
    "#Uploading dataset from 2pac\n",
    "pac_df = pd.read_csv('./unigrams_NB_clasiffiers/2pac_lyrics.csv',usecols=[1],encoding='latin-1',header=None)\n",
    "pac_df.columns = ['lyrics']\n",
    "pac_df['lyrics'] = pac_df['lyrics'].str.replace('[^\\w\\s]','')\n",
    "pac_df['lyrics'] = pac_df['lyrics'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics for biggie dataset\n",
      "                                               lyrics\n",
      "0   fuck all you hoes\\nget a grip motherfucker\\nye...\n",
      "1   as i grab the glock put it to your headpiece\\n...\n",
      "2   i dont wanna live no mo\\nsometimes i hear deat...\n",
      "3   to all the ladies in the place with style and ...\n",
      "4   nineteenseventy somethin nigga i dont sweat th...\n",
      "5   another day in the ghetto \\none look outside i...\n",
      "6   live from bedfordstuyverson the livest one\\nre...\n",
      "7   uh uh uh cmon\\nhah sicker than your average\\np...\n",
      "8   uhh uhhh\\nbig po ppa\\nno info for the dea\\nfed...\n",
      "9   uhh its the ten crack commandments\\nwhat uhh u...\n",
      "10  the commission\\nuncle paulie big ditti\\ncaesar...\n",
      "11  relax and take notes while i take tokes of the...\n",
      "12  good evenin ladies and gentlemen\\nhows everybo...\n",
      "13  who shot ya\\nseperate the weak from the obsole...\n",
      "14  when i die fuck it i wanna go to hell\\ncause i...\n",
      "15  when the lala hits ya lyrics just splits ya\\nh...\n",
      "\n",
      "Lyrics for 2pac dataset\n",
      "                                               lyrics\n",
      "0   little something for my godson elijah\\nand a l...\n",
      "1   yo mo bee mayn drop that shit\\nyou know what t...\n",
      "2   rest in peace to my motherfucker biggy smallz\\...\n",
      "3   makaveli in this killuminati\\nall through your...\n",
      "4   its just me against the world\\nnothin to lose\\...\n",
      "5   i love the way you activate your hips and push...\n",
      "6   i shall not fear no man but god\\nthough i walk...\n",
      "7   unconditional love no doubt\\ntalking bout the ...\n",
      "8   big syke newt hank\\nbeugard big sur\\nyall know...\n",
      "9   you know they got me trapped in this prison of...\n",
      "10  how many brothers fell victim to the streets\\n...\n",
      "11  i aint got no motherfucking friends\\nthats why...\n",
      "12  troublesome nigga\\nhahaha troublesome 19mother...\n",
      "13  change shit\\ni guess change is good for any of...\n",
      "14  i see no changes wake up in the morning and i ...\n",
      "15  out on bail fresh out of jail california dream...\n"
     ]
    }
   ],
   "source": [
    "valuesBiggie,values2pac = biggie_df.get_values(),pac_df.get_values()\n",
    "print(\"Lyrics for biggie dataset\")\n",
    "print(biggie_df)\n",
    "print(\"\\nLyrics for 2pac dataset\")\n",
    "print(pac_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing labels by numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for the rap lines\n",
      "(1970, 2)\n",
      "[[0 'fuck all you hoes']\n",
      " [0 'get a grip motherfucker']\n",
      " [0 'yeah this album is dedicated to all the teachers that told me']\n",
      " ...\n",
      " [1 'let me serenade the streets of la']\n",
      " [1 'from oakland to sactown the bay area and back down']\n",
      " [1 'cali is where they put their mack down']]\n"
     ]
    }
   ],
   "source": [
    "biggie_lyrics = biggie_df['lyrics'].values\n",
    "biggie_lyrics = [song.split('\\n') for song in biggie_lyrics]\n",
    "biggie_lyrics = [line for song in biggie_lyrics for line in song]\n",
    "pac_lyrics = pac_df['lyrics'].values\n",
    "pac_lyrics = [song.split('\\n') for song in pac_lyrics]\n",
    "pac_lyrics = [line for song in pac_lyrics for line in song]\n",
    "\n",
    "rap_lines = []\n",
    "\n",
    "for line in biggie_lyrics:\n",
    "    if len(line.split()) > 3:\n",
    "        rap_lines.append(np.array([0,line]))\n",
    "\n",
    "for line in pac_lyrics:\n",
    "    if len(line.split()) > 3:\n",
    "        rap_lines.append(np.array([1,line]))\n",
    "\n",
    "rap_lines = np.array(rap_lines)\n",
    "\n",
    "#Getting the dataframe\n",
    "df = pd.DataFrame(rap_lines)\n",
    "df.columns = ['label','line']\n",
    "df.head()\n",
    "df['label'] = df['label'].replace(['0','1'],[0,1])\n",
    "\n",
    "values = df.get_values()\n",
    "print(\"Values for the rap lines\")\n",
    "print(df.shape)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert all characters in the message to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines in lower-case for rap lines\n",
      "0                                       fuck all you hoes\n",
      "1                                 get a grip motherfucker\n",
      "2       yeah this album is dedicated to all the teache...\n",
      "3       id never amount to nothin to all the people th...\n",
      "4       buildings that i was hustlin in front of that ...\n",
      "5       me when i was just tryin to make some money to...\n",
      "6       and all the niggas in the struggle you know wh...\n",
      "7                        uhha its all good baby baybee uh\n",
      "8                                      it was all a dream\n",
      "9                         i used to read word up magazine\n",
      "10              saltnpepa and heavy d up in the limousine\n",
      "11                             hangin pictures on my wall\n",
      "12         every saturday rap attack mr magic marley marl\n",
      "13                     i let my tape rock til my tape pop\n",
      "14         smokin weed and bamboo sippin on private stock\n",
      "15       way back when i had the red and black lumberjack\n",
      "16                                  with the hat to match\n",
      "17                       remember rappin duke duhha duhha\n",
      "18      you never thought that hip hop would take it t...\n",
      "19            now im in the limelight cause i rhyme tight\n",
      "20          time to get paid blow up like the world trade\n",
      "21                   born sinner the opposite of a winner\n",
      "22        remember when i used to eat sardines for dinner\n",
      "23                      peace to ron g brucey b kid capri\n",
      "24                        funkmaster flex lovebug starsky\n",
      "25                  im blowin up like you thought i would\n",
      "26                    call the crib same number same hood\n",
      "27          uh and if you dont know now you know nigga uh\n",
      "28                         you know very well who you are\n",
      "29          dont let em hold you down reach for the stars\n",
      "                              ...                        \n",
      "1940                  dont let em jack you up back you up\n",
      "1941                    crack you up and pimpsmack you up\n",
      "1942                     you gotta learn to hold your own\n",
      "1943    they get jealous when they see you with your m...\n",
      "1944               but tell the cops they cant touch this\n",
      "1945    i dont trust this when they try to rush i bust...\n",
      "1946                           thats the sound of my tool\n",
      "1947     you say it aint cool my mama didnt raise no fool\n",
      "1948    and as long as i stay black i gotta stay strapped\n",
      "1949                          and i never get to lay back\n",
      "1950         cause i always got to worry bout the payback\n",
      "1951                 some buck that i roughed up way back\n",
      "1952                    coming back after all these years\n",
      "1953                 ratatattattattat thats the way it is\n",
      "1954    out on bail fresh out of jail california dreaming\n",
      "1955    soon as i step on the scene im hearing hoochie...\n",
      "1956                       fiending for money and alcohol\n",
      "1957    the life of a westside player where cowards di...\n",
      "1958    only in cali where we riot not rally to live a...\n",
      "1959    in la we wearing chucks not ballys yeah thats ...\n",
      "1960    dressed in locs and khaki suits and ride is wh...\n",
      "1961    flossing but have caution we collide with othe...\n",
      "1962                            famous because we program\n",
      "1963    worldwide let them recognize from long beach t...\n",
      "1964    bumping and grinding like a slow jam its westside\n",
      "1965          so you know the row wont bow down to no man\n",
      "1966    say what you say but give me that bomb beat fr...\n",
      "1967                    let me serenade the streets of la\n",
      "1968    from oakland to sactown the bay area and back ...\n",
      "1969               cali is where they put their mack down\n",
      "Name: line, Length: 1970, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['line'] = df['line'].str.lower()\n",
    "print(\"Lines in lower-case for rap lines\")\n",
    "print(df['line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing the messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to import and download the tokenizer from the console:\n",
    "An installation window will appear. Go to the \"Models\" tab and select \"punkt\" from the \"Identifier\" column. Then click \"Download\" and it will install the necessary files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines after tokenization for rap lines\n",
      "0                                  [fuck, all, you, hoes]\n",
      "1                            [get, a, grip, motherfucker]\n",
      "2       [yeah, this, album, is, dedicated, to, all, th...\n",
      "3       [id, never, amount, to, nothin, to, all, the, ...\n",
      "4       [buildings, that, i, was, hustlin, in, front, ...\n",
      "5       [me, when, i, was, just, tryin, to, make, some...\n",
      "6       [and, all, the, niggas, in, the, struggle, you...\n",
      "7                [uhha, its, all, good, baby, baybee, uh]\n",
      "8                                [it, was, all, a, dream]\n",
      "9                 [i, used, to, read, word, up, magazine]\n",
      "10      [saltnpepa, and, heavy, d, up, in, the, limous...\n",
      "11                       [hangin, pictures, on, my, wall]\n",
      "12      [every, saturday, rap, attack, mr, magic, marl...\n",
      "13           [i, let, my, tape, rock, til, my, tape, pop]\n",
      "14      [smokin, weed, and, bamboo, sippin, on, privat...\n",
      "15      [way, back, when, i, had, the, red, and, black...\n",
      "16                            [with, the, hat, to, match]\n",
      "17                 [remember, rappin, duke, duhha, duhha]\n",
      "18      [you, never, thought, that, hip, hop, would, t...\n",
      "19      [now, im, in, the, limelight, cause, i, rhyme,...\n",
      "20      [time, to, get, paid, blow, up, like, the, wor...\n",
      "21           [born, sinner, the, opposite, of, a, winner]\n",
      "22      [remember, when, i, used, to, eat, sardines, f...\n",
      "23             [peace, to, ron, g, brucey, b, kid, capri]\n",
      "24                   [funkmaster, flex, lovebug, starsky]\n",
      "25         [im, blowin, up, like, you, thought, i, would]\n",
      "26            [call, the, crib, same, number, same, hood]\n",
      "27      [uh, and, if, you, dont, know, now, you, know,...\n",
      "28                 [you, know, very, well, who, you, are]\n",
      "29      [dont, let, em, hold, you, down, reach, for, t...\n",
      "                              ...                        \n",
      "1940        [dont, let, em, jack, you, up, back, you, up]\n",
      "1941            [crack, you, up, and, pimpsmack, you, up]\n",
      "1942           [you, got, ta, learn, to, hold, your, own]\n",
      "1943    [they, get, jealous, when, they, see, you, wit...\n",
      "1944      [but, tell, the, cops, they, cant, touch, this]\n",
      "1945    [i, dont, trust, this, when, they, try, to, ru...\n",
      "1946                    [thats, the, sound, of, my, tool]\n",
      "1947    [you, say, it, aint, cool, my, mama, didnt, ra...\n",
      "1948    [and, as, long, as, i, stay, black, i, got, ta...\n",
      "1949                  [and, i, never, get, to, lay, back]\n",
      "1950    [cause, i, always, got, to, worry, bout, the, ...\n",
      "1951        [some, buck, that, i, roughed, up, way, back]\n",
      "1952             [coming, back, after, all, these, years]\n",
      "1953          [ratatattattattat, thats, the, way, it, is]\n",
      "1954    [out, on, bail, fresh, out, of, jail, californ...\n",
      "1955    [soon, as, i, step, on, the, scene, im, hearin...\n",
      "1956                 [fiending, for, money, and, alcohol]\n",
      "1957    [the, life, of, a, westside, player, where, co...\n",
      "1958    [only, in, cali, where, we, riot, not, rally, ...\n",
      "1959    [in, la, we, wearing, chucks, not, ballys, yea...\n",
      "1960    [dressed, in, locs, and, khaki, suits, and, ri...\n",
      "1961    [flossing, but, have, caution, we, collide, wi...\n",
      "1962                       [famous, because, we, program]\n",
      "1963    [worldwide, let, them, recognize, from, long, ...\n",
      "1964    [bumping, and, grinding, like, a, slow, jam, i...\n",
      "1965    [so, you, know, the, row, wont, bow, down, to,...\n",
      "1966    [say, what, you, say, but, give, me, that, bom...\n",
      "1967            [let, me, serenade, the, streets, of, la]\n",
      "1968    [from, oakland, to, sactown, the, bay, area, a...\n",
      "1969      [cali, is, where, they, put, their, mack, down]\n",
      "Name: line, Length: 1970, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['line'] = df['line'].apply(nltk.word_tokenize)\n",
    "print(\"Lines after tokenization for rap lines\")\n",
    "print(df['line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming the messages using the Porter Stemmer algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines after stemming for rap lines\n",
      "0                                   [fuck, all, you, hoe]\n",
      "1                              [get, a, grip, motherfuck]\n",
      "2       [yeah, thi, album, is, dedic, to, all, the, te...\n",
      "3       [id, never, amount, to, nothin, to, all, the, ...\n",
      "4       [build, that, i, wa, hustlin, in, front, of, t...\n",
      "5       [me, when, i, wa, just, tryin, to, make, some,...\n",
      "6       [and, all, the, nigga, in, the, struggl, you, ...\n",
      "7                  [uhha, it, all, good, babi, baybe, uh]\n",
      "8                                 [it, wa, all, a, dream]\n",
      "9                   [i, use, to, read, word, up, magazin]\n",
      "10      [saltnpepa, and, heavi, d, up, in, the, limousin]\n",
      "11                         [hangin, pictur, on, my, wall]\n",
      "12      [everi, saturday, rap, attack, mr, magic, marl...\n",
      "13           [i, let, my, tape, rock, til, my, tape, pop]\n",
      "14      [smokin, weed, and, bamboo, sippin, on, privat...\n",
      "15      [way, back, when, i, had, the, red, and, black...\n",
      "16                            [with, the, hat, to, match]\n",
      "17                   [rememb, rappin, duke, duhha, duhha]\n",
      "18      [you, never, thought, that, hip, hop, would, t...\n",
      "19      [now, im, in, the, limelight, caus, i, rhyme, ...\n",
      "20      [time, to, get, paid, blow, up, like, the, wor...\n",
      "21            [born, sinner, the, opposit, of, a, winner]\n",
      "22      [rememb, when, i, use, to, eat, sardin, for, d...\n",
      "23              [peac, to, ron, g, brucey, b, kid, capri]\n",
      "24                     [funkmast, flex, lovebug, starski]\n",
      "25         [im, blowin, up, like, you, thought, i, would]\n",
      "26            [call, the, crib, same, number, same, hood]\n",
      "27      [uh, and, if, you, dont, know, now, you, know,...\n",
      "28                 [you, know, veri, well, who, you, are]\n",
      "29      [dont, let, em, hold, you, down, reach, for, t...\n",
      "                              ...                        \n",
      "1940        [dont, let, em, jack, you, up, back, you, up]\n",
      "1941            [crack, you, up, and, pimpsmack, you, up]\n",
      "1942           [you, got, ta, learn, to, hold, your, own]\n",
      "1943    [they, get, jealou, when, they, see, you, with...\n",
      "1944        [but, tell, the, cop, they, cant, touch, thi]\n",
      "1945    [i, dont, trust, thi, when, they, tri, to, rus...\n",
      "1946                     [that, the, sound, of, my, tool]\n",
      "1947    [you, say, it, aint, cool, my, mama, didnt, ra...\n",
      "1948    [and, as, long, as, i, stay, black, i, got, ta...\n",
      "1949                  [and, i, never, get, to, lay, back]\n",
      "1950    [caus, i, alway, got, to, worri, bout, the, pa...\n",
      "1951          [some, buck, that, i, rough, up, way, back]\n",
      "1952                [come, back, after, all, these, year]\n",
      "1953           [ratatattattattat, that, the, way, it, is]\n",
      "1954    [out, on, bail, fresh, out, of, jail, californ...\n",
      "1955    [soon, as, i, step, on, the, scene, im, hear, ...\n",
      "1956                    [fiend, for, money, and, alcohol]\n",
      "1957    [the, life, of, a, westsid, player, where, cow...\n",
      "1958    [onli, in, cali, where, we, riot, not, ralli, ...\n",
      "1959    [in, la, we, wear, chuck, not, balli, yeah, th...\n",
      "1960    [dress, in, loc, and, khaki, suit, and, ride, ...\n",
      "1961    [floss, but, have, caution, we, collid, with, ...\n",
      "1962                         [famou, becaus, we, program]\n",
      "1963    [worldwid, let, them, recogn, from, long, beac...\n",
      "1964    [bump, and, grind, like, a, slow, jam, it, wes...\n",
      "1965    [so, you, know, the, row, wont, bow, down, to,...\n",
      "1966    [say, what, you, say, but, give, me, that, bom...\n",
      "1967              [let, me, serenad, the, street, of, la]\n",
      "1968    [from, oakland, to, sactown, the, bay, area, a...\n",
      "1969      [cali, is, where, they, put, their, mack, down]\n",
      "Name: line, Length: 1970, dtype: object\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "df['line'] = df['line'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "print(\"Lines after stemming for rap lines\")\n",
    "print(df['line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming data into occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and lines for rap lines\n",
      "0                                        fuck all you hoe\n",
      "1                                   get a grip motherfuck\n",
      "2       yeah thi album is dedic to all the teacher tha...\n",
      "3       id never amount to nothin to all the peopl tha...\n",
      "4       build that i wa hustlin in front of that call ...\n",
      "5       me when i wa just tryin to make some money to ...\n",
      "6       and all the nigga in the struggl you know what...\n",
      "7                          uhha it all good babi baybe uh\n",
      "8                                       it wa all a dream\n",
      "9                           i use to read word up magazin\n",
      "10               saltnpepa and heavi d up in the limousin\n",
      "11                               hangin pictur on my wall\n",
      "12         everi saturday rap attack mr magic marley marl\n",
      "13                     i let my tape rock til my tape pop\n",
      "14          smokin weed and bamboo sippin on privat stock\n",
      "15       way back when i had the red and black lumberjack\n",
      "16                                  with the hat to match\n",
      "17                         rememb rappin duke duhha duhha\n",
      "18      you never thought that hip hop would take it t...\n",
      "19             now im in the limelight caus i rhyme tight\n",
      "20          time to get paid blow up like the world trade\n",
      "21                    born sinner the opposit of a winner\n",
      "22             rememb when i use to eat sardin for dinner\n",
      "23                       peac to ron g brucey b kid capri\n",
      "24                          funkmast flex lovebug starski\n",
      "25                  im blowin up like you thought i would\n",
      "26                    call the crib same number same hood\n",
      "27          uh and if you dont know now you know nigga uh\n",
      "28                         you know veri well who you are\n",
      "29           dont let em hold you down reach for the star\n",
      "                              ...                        \n",
      "1940                  dont let em jack you up back you up\n",
      "1941                    crack you up and pimpsmack you up\n",
      "1942                    you got ta learn to hold your own\n",
      "1943    they get jealou when they see you with your mo...\n",
      "1944                 but tell the cop they cant touch thi\n",
      "1945    i dont trust thi when they tri to rush i bust thi\n",
      "1946                            that the sound of my tool\n",
      "1947      you say it aint cool my mama didnt rais no fool\n",
      "1948      and as long as i stay black i got ta stay strap\n",
      "1949                          and i never get to lay back\n",
      "1950           caus i alway got to worri bout the payback\n",
      "1951                   some buck that i rough up way back\n",
      "1952                       come back after all these year\n",
      "1953                  ratatattattattat that the way it is\n",
      "1954       out on bail fresh out of jail california dream\n",
      "1955    soon as i step on the scene im hear hoochi scream\n",
      "1956                          fiend for money and alcohol\n",
      "1957    the life of a westsid player where coward die ...\n",
      "1958    onli in cali where we riot not ralli to live a...\n",
      "1959        in la we wear chuck not balli yeah that right\n",
      "1960    dress in loc and khaki suit and ride is what w...\n",
      "1961     floss but have caution we collid with other crew\n",
      "1962                              famou becaus we program\n",
      "1963    worldwid let them recogn from long beach to ro...\n",
      "1964            bump and grind like a slow jam it westsid\n",
      "1965          so you know the row wont bow down to no man\n",
      "1966    say what you say but give me that bomb beat fr...\n",
      "1967                      let me serenad the street of la\n",
      "1968    from oakland to sactown the bay area and back ...\n",
      "1969               cali is where they put their mack down\n",
      "Name: line, Length: 1970, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['line'] = df['line'].apply(lambda x: ' '.join(x))\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "print(\"Counts and lines for rap lines\")\n",
    "counts = count_vect.fit_transform(df['line'])\n",
    "#print(count_vect.get_feature_names())\n",
    "#print(counts.toarray())\n",
    "print(df['line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Term Frequency Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts after transforming for rap lines\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fercho\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "transformer = TfidfTransformer().fit(counts)\n",
    "counts = transformer.transform(counts)\n",
    "\n",
    "print(\"Counts after transforming for rap lines\")\n",
    "print(counts.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Initializing Multinomial Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data into training and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(counts, df['label'], test_size=.1)\n",
    "#x_train = counts[:4]\n",
    "#x_test = counts[4:5]\n",
    "#y_train = pd.Series(df.get_values()[0:4][:,0])\n",
    "#y_test = pd.Series(df.get_values()[4:5][:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for rap lines\n",
      "The model got 70.05076142131979% Accuracy\n",
      "Predicted class: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
      " 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
      " 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0\n",
      " 0 1 1 1 1 0 1 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "predicted = model.fit(x_train, y_train)\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "print(\"Results for rap lines\")\n",
    "print(\"The model got \" + str(100*np.mean(predicted == y_test)) + \"% Accuracy\")\n",
    "print(\"Predicted class: \" + str(predicted))\n",
    "#print(\"Probabilities for each class: \" + str(model.predict_proba(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model got 61.92893401015228% Accuracy\n",
      "The model got 71.57360406091371% Accuracy\n",
      "The model got 69.54314720812182% Accuracy\n",
      "The model got 68.02030456852792% Accuracy\n",
      "The model got 68.52791878172589% Accuracy\n",
      "The model got 73.09644670050761% Accuracy\n",
      "The model got 74.61928934010153% Accuracy\n",
      "The model got 70.55837563451777% Accuracy\n",
      "The model got 72.08121827411168% Accuracy\n",
      "The model got 69.03553299492386% Accuracy\n",
      "Average Accuracy: 0.70\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for _ in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(counts, df['label'], test_size=.1)\n",
    "    predicted = model.fit(x_train, y_train)\n",
    "    predicted = model.predict(x_test)\n",
    "    res = (np.mean(predicted == y_test))\n",
    "    print(\"The model got \" + str(100*res) + \"% Accuracy\")\n",
    "    results.append(res)\n",
    "    \n",
    "print(\"Average Accuracy: {:.2f}\".format(sum(results)/float(len(results))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
