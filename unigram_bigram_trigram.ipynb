{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigrams, bigrams, and trigrams in Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0\n",
      "  'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...']\n",
      " [0 'Ok lar... Joking wif u oni...']\n",
      " [1\n",
      "  \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"]\n",
      " ...\n",
      " [0 'Pity, * was in mood for that. So...any other suggestions?']\n",
      " [0\n",
      "  \"The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free\"]\n",
      " [0 'Rofl. Its true to its name']]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./unigrams_NB_clasiffiers/spamSMS.csv', usecols = [0,1], encoding = 'latin-1')\n",
    "df.columns = ['label','body']\n",
    "#label spam as 1, not spam as 0\n",
    "df['label'] = df['label'].replace(['ham','spam'],[0,1])\n",
    "data = df.values\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ngrams_bayes():\n",
    "    \n",
    "    def __init__(self,data,n=2,split=.75):\n",
    "        \n",
    "        #split into training and testing data\n",
    "        self.train_data, self.test_data = train_test_split(data, \n",
    "                                                           train_size = split)\n",
    "        #convert into n grams\n",
    "        self.train_data = [[item[0], self.ngrams(n, item[1])] for item in self.train_data]\n",
    "        self.test_data = [[item[0], self.ngrams(n, item[1])] for item in self.test_data]\n",
    "        \n",
    "        #count unique n grams in training data\n",
    "        flattened = [gram for message in self.train_data for gram in message[1]]\n",
    "        self.unique = len(set(flattened))\n",
    "        \n",
    "        #init dicts\n",
    "        self.trainPositive = {}\n",
    "        self.trainNegative = {}\n",
    "        #counters \n",
    "        self.posGramCount = 0\n",
    "        self.negGramCount = 0\n",
    "        self.spamCount = 0\n",
    "        #priors\n",
    "        self.pA = 0\n",
    "        self.pNotA = 0\n",
    "    \n",
    "    def ngrams(self,n,text):\n",
    "        text = text.split(' ')\n",
    "        grams = []\n",
    "        for i in range(len(text)-n+1):\n",
    "            gram = ' '.join(text[i:i+n])\n",
    "            grams.append(gram)\n",
    "        return grams\n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        for item in self.train_data:\n",
    "            label = item[0]\n",
    "            grams = item[1]\n",
    "            if label == 1:\n",
    "                self.spamCount +=1\n",
    "            for gram in grams:\n",
    "                if label == 1:\n",
    "                    self.trainPositive[gram] = self.trainPositive.get(gram,0) + 1\n",
    "                    self.posGramCount += 1\n",
    "                else:\n",
    "                    self.trainNegative[gram] = self.trainNegative.get(gram,0) + 1\n",
    "                    self.negGramCount += 1\n",
    "            \n",
    "            self.pA = self.spamCount / float(len(self.train_data))\n",
    "            self.pNotA = 1.0 - self.pA\n",
    "    \n",
    "    def classify(self,text,alpha=1.0):\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        isSpam = self.pA * self.conditionalText(text,1)\n",
    "        notSpam = self.pNotA * self.conditionalText(text,0)\n",
    "        if(isSpam > notSpam):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def conditionalText(self,grams,label):\n",
    "        result = 1.0\n",
    "        for ngram in grams:\n",
    "            result *= self.conditionalNgram(ngram,label)\n",
    "        return result\n",
    "    \n",
    "    def conditionalNgram(self,ngram,label):\n",
    "        alpha = self.alpha\n",
    "        if label == 1:\n",
    "            return ((self.trainPositive.get(ngram,0)+alpha)/\n",
    "                    float(self.posGramCount+alpha*self.unique))\n",
    "        \n",
    "        else:\n",
    "            return ((self.trainNegative.get(ngram,0)+alpha)/\n",
    "                    float(self.negGramCount+alpha*self.unique))\n",
    "    \n",
    "    def evaluate_test_data(self):\n",
    "        results = []\n",
    "        for test in self.test_data:\n",
    "            label = test[0]\n",
    "            text = test[1]\n",
    "            ruling = self.classify(text)\n",
    "            if ruling == label:\n",
    "                results.append(0)\n",
    "            else:\n",
    "                results.append(1)\n",
    "        \n",
    "        print(\"Evaluated {} test cases. {:.2f}% Accuracy\".format(len(results),100.0*sum(results)/\n",
    "    float(len(results))))\n",
    "        return sum(results)/float(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "[0, ['Sure,', \"I'll\", 'see', 'if', 'I', 'can', 'come', 'by', 'in', 'a', 'bit']]\n",
      "12937\n"
     ]
    }
   ],
   "source": [
    "unigram_bayes = ngrams_bayes(data,1)\n",
    "print(unigram_bayes.trainPositive)\n",
    "unigram_bayes.train()\n",
    "print(unigram_bayes.test_data[0])\n",
    "print(unigram_bayes.unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram_bayes.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 1393 test cases. 3.95% Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03948312993539124"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_bayes.evaluate_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 1393 test cases. 26.35% Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.26346015793251976"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_sms = ngrams_bayes(data,2)\n",
    "bigram_sms.train()\n",
    "bigram_sms.evaluate_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 1393 test cases. 52.40% Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5240488155061019"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_sms = ngrams_bayes(data,3)\n",
    "trigram_sms.train()\n",
    "trigram_sms.evaluate_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naives Bayes Classifier for distinguishing between lines from Biggie Smalls and 2Pac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biggie_df = pd.read_csv('./unigrams_NB_clasiffiers/biggie_lyrics.csv',usecols=[1],encoding='latin-1',header=None)\n",
    "biggie_df.columns = ['lyrics']\n",
    "biggie_df['lyrics'] = biggie_df['lyrics'].str.replace('[^\\w\\s]','')\n",
    "biggie_df['lyrics'] = biggie_df['lyrics'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>relax and take notes while i take tokes of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>good evenin ladies and gentlemen\\nhows everybo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>who shot ya\\nseperate the weak from the obsole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>when i die fuck it i wanna go to hell\\ncause i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>when the lala hits ya lyrics just splits ya\\nh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               lyrics\n",
       "11  relax and take notes while i take tokes of the...\n",
       "12  good evenin ladies and gentlemen\\nhows everybo...\n",
       "13  who shot ya\\nseperate the weak from the obsole...\n",
       "14  when i die fuck it i wanna go to hell\\ncause i...\n",
       "15  when the lala hits ya lyrics just splits ya\\nh..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biggie_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pac_df = pd.read_csv('./unigrams_NB_clasiffiers/2pac_lyrics.csv',usecols=[1],encoding='latin-1',header=None)\n",
    "pac_df.columns = ['lyrics']\n",
    "pac_df['lyrics'] = pac_df['lyrics'].str.replace('[^\\w\\s]','')\n",
    "pac_df['lyrics'] = pac_df['lyrics'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little something for my godson elijah\\nand a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yo mo bee mayn drop that shit\\nyou know what t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rest in peace to my motherfucker biggy smallz\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>makaveli in this killuminati\\nall through your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>its just me against the world\\nnothin to lose\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics\n",
       "0  little something for my godson elijah\\nand a l...\n",
       "1  yo mo bee mayn drop that shit\\nyou know what t...\n",
       "2  rest in peace to my motherfucker biggy smallz\\...\n",
       "3  makaveli in this killuminati\\nall through your...\n",
       "4  its just me against the world\\nnothin to lose\\..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biggie_lyrics = biggie_df['lyrics'].values\n",
    "biggie_lyrics = [song.split('\\n') for song in biggie_lyrics]\n",
    "biggie_lyrics = [line for song in biggie_lyrics for line in song]\n",
    "pac_lyrics = pac_df['lyrics'].values\n",
    "pac_lyrics = [song.split('\\n') for song in pac_lyrics]\n",
    "pac_lyrics = [line for song in pac_lyrics for line in song]\n",
    "\n",
    "rap_lines = []\n",
    "\n",
    "for line in biggie_lyrics:\n",
    "    if len(line.split()) > 3:\n",
    "        rap_lines.append(np.array([0,line]))\n",
    "\n",
    "for line in pac_lyrics:\n",
    "    if len(line.split()) > 3:\n",
    "        rap_lines.append(np.array([1,line]))\n",
    "\n",
    "rap_lines = np.array(rap_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rap_lines = pd.DataFrame(rap_lines)\n",
    "rap_lines.columns = ['label','line']\n",
    "rap_lines.head()\n",
    "rap_lines['label'] = rap_lines['label'].replace(['0','1'],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_biggie_vs_pac = ngrams_bayes(rap_lines.values,1,.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_biggie_vs_pac.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 197 test cases. 29.95% Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.29949238578680204"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_biggie_vs_pac.evaluate_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 197 test cases. 25.89% Accuracy\n",
      "Evaluated 197 test cases. 24.37% Accuracy\n",
      "Evaluated 197 test cases. 27.92% Accuracy\n",
      "Evaluated 197 test cases. 29.44% Accuracy\n",
      "Evaluated 197 test cases. 25.38% Accuracy\n",
      "Evaluated 197 test cases. 24.37% Accuracy\n",
      "Evaluated 197 test cases. 29.44% Accuracy\n",
      "Evaluated 197 test cases. 26.40% Accuracy\n",
      "Evaluated 197 test cases. 27.41% Accuracy\n",
      "Evaluated 197 test cases. 24.87% Accuracy\n",
      "Average Accuracy: 0.27\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for _ in range(10):\n",
    "    unigram = ngrams_bayes(rap_lines.values,1,.9)\n",
    "    unigram.train()\n",
    "    results.append(unigram.evaluate_test_data())\n",
    "    \n",
    "print(\"Average Accuracy: {:.2f}\".format(sum(results)/float(len(results))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 197 test cases. 21.83% Accuracy\n",
      "Evaluated 197 test cases. 20.30% Accuracy\n",
      "Evaluated 197 test cases. 24.87% Accuracy\n",
      "Evaluated 197 test cases. 19.29% Accuracy\n",
      "Evaluated 197 test cases. 27.92% Accuracy\n",
      "Evaluated 197 test cases. 22.34% Accuracy\n",
      "Evaluated 197 test cases. 27.41% Accuracy\n",
      "Evaluated 197 test cases. 23.35% Accuracy\n",
      "Evaluated 197 test cases. 29.95% Accuracy\n",
      "Evaluated 197 test cases. 30.46% Accuracy\n",
      "Average Accuracy: 0.25\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for _ in range(10):\n",
    "    bigram = ngrams_bayes(rap_lines.values,1,.9)\n",
    "    bigram.train()\n",
    "    results.append(bigram.evaluate_test_data())\n",
    "    \n",
    "print(\"Average Accuracy: {:.2f}\".format(sum(results)/float(len(results))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 197 test cases. 29.95% Accuracy\n",
      "Evaluated 197 test cases. 26.40% Accuracy\n",
      "Evaluated 197 test cases. 24.37% Accuracy\n",
      "Evaluated 197 test cases. 26.40% Accuracy\n",
      "Evaluated 197 test cases. 22.84% Accuracy\n",
      "Evaluated 197 test cases. 25.38% Accuracy\n",
      "Evaluated 197 test cases. 27.92% Accuracy\n",
      "Evaluated 197 test cases. 23.35% Accuracy\n",
      "Evaluated 197 test cases. 25.38% Accuracy\n",
      "Evaluated 197 test cases. 19.29% Accuracy\n",
      "Average Accuracy: 0.25\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for _ in range(10):\n",
    "    trigram = ngrams_bayes(rap_lines.values,1,.9)\n",
    "    trigram.train()\n",
    "    results.append(trigram.evaluate_test_data())\n",
    "    \n",
    "print(\"Average Accuracy: {:.2f}\".format(sum(results)/float(len(results))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
